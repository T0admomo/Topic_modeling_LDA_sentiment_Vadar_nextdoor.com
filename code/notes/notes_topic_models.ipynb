{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c6477e-b2cd-4e77-bef6-fd2550fd82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54c434c-5b0c-4a96-9d1f-2f50bb5fcb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = pd.read_csv('../data/all_posts.csv')\n",
    "posts = posts['post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af1313-5910-4e14-b2bf-25bf7f4ca0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using spacy for preprocessing\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce40d1f-7a4f-434d-b60f-8f9cda247f9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260f75ce-832f-4fbf-9b4e-ff701a73804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb74a03-8060-4fd9-8555-cca48d53b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding words to spacy pipeline stopword list \n",
    "my_stop_words = ['say', 's', 'Mr', 'be', 'said', 'says', 'saying']\n",
    "for stopword in my_stop_words:\n",
    "    # add stop word to vocabulary \n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    # mark as stop word\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2b36a-9a0c-4cba-b2e3-ed66ca0ba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = lemmatization(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c657211-b3ef-4c3d-ac1c-4a80f09a7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2d991-0eeb-448d-a1d6-ff3200f293e0",
   "metadata": {},
   "source": [
    "It seems like nothing, right? But spaCy's internal data structure has done all the work for us. Let's see how we can create our corpus. You can check out what a gensim corpus looks like here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66d5dc1-4884-4976-96e9-f73062a5163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words and taking the lemma\n",
    "\n",
    "texts, article, skl_texts = [], [], []\n",
    "for w in doc:\n",
    "    # if it's not a stop word or punctuation mark, add it to our article!\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "        # we add the lematized version of the word\n",
    "        article.append(w.lemma_)\n",
    "    # if it's a new line, it means we're onto our next document\n",
    "    if w.text == '\\n':\n",
    "        skl_texts.append(' '.join(article))\n",
    "        texts.append(article)\n",
    "        article = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bcf09-ffeb-4db2-8a80-04e0b4b8eccd",
   "metadata": {},
   "source": [
    "# Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f7346-5677-4e4b-8f49-a59987317862",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(texts)\n",
    "texts = [bigram[line] for line in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea524514-f07c-4e74-824f-112895400090",
   "metadata": {},
   "source": [
    "# Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c711f8e6-a4b5-4d1c-9c49-7987c96c7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f5014-adc2-4bc6-be54-468d520b5682",
   "metadata": {},
   "source": [
    "# LSI\n",
    "\n",
    "LSI stands for Latent Semantic Indeixing - it is a popular information retreival method which works by decomposing the original matrix of words to maintain key topics. Gensim's implementation uses an SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6ae0c-d3cd-46ec-9b83-e072d00f2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "lsimodel.show_topics(num_topics=5)  # Showing only the top 5 topics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84118b69-5c85-4bde-9021-9315070d6235",
   "metadata": {},
   "source": [
    "# HDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be257e-1a96-45e4-b381-de640b22ab69",
   "metadata": {},
   "source": [
    "HDP, the Hierarchical Dirichlet process is an unsupervised topic model which figures out the number of topics on it's own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebc046-561d-4ae8-a83f-e38118caa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3c6e2-f088-482b-83e9-7d7f87bde1bc",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2587056-656e-4b8b-bec3-57a70c8abba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "\n",
    "ldamodel.show_topics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6213eed-8d71-4328-897d-a85b806434c7",
   "metadata": {},
   "source": [
    "# SKLearn NMF & LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3146ffde-6dc5-4c78-a9d8-dedbd7c5a86b",
   "metadata": {},
   "source": [
    "Let us now use NMF and LDA which is available in sklearn to see how these topics work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57406a-4a8e-4f82-87b6-a0238a65fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ea01c-8207-4022-9233-53019e511911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11aa87-33f6-43ca-bc83-1d78ed88674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic %d:\" % (topic_idx)\n",
    "        print \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])\n",
    "\n",
    "# dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "# documents = dataset.data\n",
    "\n",
    "no_features = 1000\n",
    "\n",
    "# NMF is able to use tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(skl_texts)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(skl_texts)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "no_topics = 10\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\n",
    "\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)\n",
    "display_topics(lda, tf_feature_names, no_top_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213805a-7b46-418f-a5da-26d0eef21f22",
   "metadata": {},
   "source": [
    "# pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125d4de-863c-4bf1-bdb1-641582d3540d",
   "metadata": {},
   "source": [
    "Thanks to pyLDAvis, we can visualise our topic models in a really handy way. All we need to do is enable our notebook and prepare the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa629b92-417f-428f-8850-074d5ed95b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45bbde-bade-4a31-9fa6-ba4052a6d813",
   "metadata": {},
   "source": [
    "\n",
    "# Round-up\n",
    "\n",
    "Okay - so what have we learned so far? By using spaCy, we cleaned up our data super fast. It's worth noting that by running our doc through the pipeline we also know about every single words POS-tag and NER-tag. This is useful information and we can do some funky things with it! I would highly recommend going through this repository to see examples of hands-on spaCy usage.\n",
    "\n",
    "As for gensim and topic modelling, it's pretty easy to see how well we could create our topic models. Now the obvious next question is - how do we use these topic models? The news classification notebook in the Gensim notebooks directory is a good example of how we can use topic models in a practical scenario.\n",
    "\n",
    "We will continue this tutorial by demonstrating a newer topic modelling features of gensim - in particular, Topic Coherence.\n",
    "\n",
    "# Topic Coherence\n",
    "\n",
    "Topic Coherence is a new gensim functionality where we can identify which topic model is 'better'. By returning a score, we can compare between different topic models of the same. We use the same example from the news classification notebook to plot a graph between the topic models we have created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d850b0-8063-413e-aa5a-1f6240e8087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
    "\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "\n",
    "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]\n",
    "\n",
    "\n",
    "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "lda_coherence = CoherenceModel(topics=ldatopics, texts=texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_bar_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    \n",
    "    coherences: list of coherence values\n",
    "    indices: Indices to be used to mark bars. Length of this and coherences should be equal.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58ad7c-0f6f-457e-b892-b15fc8bd5272",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_bar_graph([lsi_coherence, hdp_coherence, lda_coherence],\n",
    "                   ['LSI', 'HDP', 'LDA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c792340-7a0c-4711-ac9e-5482cf266e2a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can see that topic coherence helped us get past manually inspecting our topic models - we can now keep fine tuning our models and compare between them to see which has the best performance.\n",
    "\n",
    "This also brings us to the end of the runnable part of this tutorial - we will continue however by briefly going over two more Jupyter notebooks I have previously worked on - mainly, Dynamic Topic Modelling and Document Word Coloring.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('work': conda)",
   "language": "python",
   "name": "python382jvsc74a57bd08696d3c135d391e67f0eae834eacd73bc5019c07a594ec3c835ec49a48ec6a4c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
